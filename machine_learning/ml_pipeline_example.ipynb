{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline Example \n",
    "This notebook acts as an example for the use of sklearn preprocessing a preprocessing pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports, libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import regex as re\n",
    "from sklearn.preprocessing import StandardScaler, Binarizer, LabelEncoder, Normalizer, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "import os\n",
    "\n",
    "#import preprocessing.pipe as pipe\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Call preprocessing pipeline\n",
    "If import pipe fails the working directory needs to be changed to import it.\n",
    "The preprocessing_pipe-function can be transformed by changing the default parameters according to the planned ml-algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import of pipe module\n",
    "os.chdir('../preprocessing/')\n",
    "import pipe\n",
    "\n",
    "# calling preprocessing function\n",
    "df = pipe.preprocessing_pipe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Test for missing values in target feature\n",
    "The target feature cannot have missing values, else sklearn will throw an exception. The target-feature now is 'loc' aka Location."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['loc'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['loc'].notna()]  # selects only rows without missing values in target feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Train test split\n",
    "Before imputing missing values or scaling the features, a train test split should be made (utilizing sklearn.model_selection.train_test_split). Keep a representative split by using the parameter \"startify\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X = df.drop(columns=['loc']) # features\n",
    "y = df['loc'].cat.codes # target feature\n",
    "\n",
    "d = df['loc'].cat.categories\n",
    "\n",
    "\n",
    "# train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 42, stratify = y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Impute missing values and encode categorical features\n",
    "With the help of the pipe.impute_and_encode function it is now time to impute missing values based on a predefined strategy and onehotencode categorical features. The function uses the Pipeline module from sklearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter for numeric and categorical features\n",
    "numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "category = ['category']\n",
    "\n",
    "# select list of numeric and categorical features\n",
    "numeric_features = X.select_dtypes(include=numerics).columns.tolist()\n",
    "categorical_features = X.select_dtypes(include=category).columns.tolist()\n",
    "\n",
    "# define imputer strategy (consult sklarn SimpleImputer and StandardScaler documentation for options)\n",
    "imputer = {'categorical':{'strategy':'most_frequent', 'fill_value':'missing'}, 'numerical':{'strategy':'median', 'fill_value':'mean'}}\n",
    "imputer_encoder = pipe.impute_and_encode(categorical_features, numeric_features, imputer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Train a model\n",
    "For this example we train a simple DecisionTree without any parameter optimization (aka definetly overfitting). Note that imputation and encoding would actually not be necessary for a DecisionTree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sklearn imports\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree, export_graphviz\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "dectree = DecisionTreeClassifier()\n",
    "\n",
    "pipeline = Pipeline(steps=[('preprocessor', imputer_encoder),\n",
    "                      ('classifier', dectree)])\n",
    "\n",
    "# Specify the hyperparameter space\n",
    "parameters = {}\n",
    "\n",
    "# Instantiate the GridSearchCV object: cv\n",
    "cv = GridSearchCV(pipeline, parameters, cv = 5)\n",
    "\n",
    "# Fit to the training set\n",
    "t = cv.fit(X_train, y_train)\n",
    "\n",
    "# Predict the labels of the test set: y_pred\n",
    "y_pred = cv.predict(X_test)\n",
    "\n",
    "# Compute and print metrics\n",
    "print(\"Accuracy: {}\".format(cv.score(X_test, y_test)))\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "ConfusionMatrixDisplay(confusion_matrix(y_test, y_pred)).plot();\n",
    "print(cv.best_params_);\n",
    "\n",
    "plt.figure(figsize=(20,20))\n",
    "plot_tree(cv.best_estimator_['classifier'], fontsize=8)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
